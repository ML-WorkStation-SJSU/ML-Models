{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is LDA?\n",
    "\n",
    "Linear Discriminant Analysis (LDA) is a feature transformation technique as well as a supervised classifier. It is commonly used as a preprocessing step for classification pipelines.\n",
    "\n",
    "The goal of LDA, like PCA, is to extract a new coordinate system and project datasets onto a lower-dimensional space. The main difference between LDA and PCA is that instead of focusing on the variance of the data as a whole like PCA, LDA optimizes the lower-dimensional space for the best class separability. \n",
    "\n",
    "The reason that LDA is extremely useful is that separating based on class separability helps us avoid overfitting in our machine learning pipelines. This is also known as preventing the curse of dimensionality. LDA also reduces computational costs.\n",
    "\n",
    "## How LDA worksï¼Ÿ\n",
    "\n",
    "\n",
    "* Dimensionality reduction tool, like PCA\n",
    "* Unlike PCA, instead of calculating the eigenvalues of the covariance matrix of the data as a whole, LDA calculates eigenvalues and eigenvectors of within-class and between-class scatter matrices\n",
    "\n",
    "Performing LDA can be broken down into five steps:\n",
    "1. Calculate mean vectors of each class\n",
    "2. Calculate within-class and between-class scatter matrices\n",
    "3. Calculate eigenvalues and eigenvectors for $S^{-1}_wS_B$\n",
    "4. Keep the top k eigenvectors by ordering them by descending eigenvalues\n",
    "5. Use the top eigenvectors to project onto the new space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean for each class\n",
    " # to do this we will separate the iris dataset into three dataframes\n",
    " # one for each flower, then we will take one's mean columnwise\n",
    "mean_vectors = []\n",
    "for cl in [0, 1, 2]:\n",
    "class_mean_vector = np.mean(iris_X[iris_y==cl], axis=0)\n",
    "mean_vectors.append(class_mean_vector)\n",
    "print label_dict[cl], class_mean_vector\n",
    "\n",
    "setosa [ 5.006 3.418 1.464 0.244] # mean value for each feature\n",
    "versicolor [ 5.936 2.77 4.26 1.326]\n",
    "virginica [ 6.588 2.974 5.552 2.026]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate a within-class scatter matrix, defined by: \n",
    "\n",
    "![image](https://proquest-safaribooksonline-com.rpa.sccl.org/getfile?item=ODA4NzcwYXM3L3MyNmFjcmRtcHQvOGUxZ2k5N3MvYTRjLTYtNGE1MC00Y3R0c2VlL2FmZC9mc3M3Y2RzcG42Z2Y5NDlkMy1lNmM3YWUyLmY0)\n",
    "\n",
    "where $S_{i}$ is \n",
    "![image](https://proquest-safaribooksonline-com.rpa.sccl.org/getfile?item=ODA4NzcwYXM3L3MyNmFjcmRtcHQvOGUxZ2k5N3MvNTRjLTAtZThkMy1hMXR0c2VlL2EzZi9kc3M1MDVzcG4zZ2E2NWEzNy1jNzJjYzEyLjNh)\n",
    "Here, mi represents the mean vector for the i class, and a between-class scatter matrix defined by the following:\n",
    "![image](https://proquest-safaribooksonline-com.rpa.sccl.org/getfile?item=ODA4NzcwYXM3L3MyNmFjcmRtcHQvOGUxZ2k5N3MvZTQ3LWItNDQ2ZS1jYXR0c2VlL2EyOC9ic3NmNmNzcG5mZ2JjYzg1Ny1mNDRhN2RhLjNl)\n",
    "\n",
    "$m$ is the overall mean of the dataset. $m_i$ is the sample mean for each class. $N_i$ is the sample size for each class. $c$ is the number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Calculate within-class scatter matrix\n",
    "S_W = np.zeros((4,4)) # in total 4 features therefore the convariance matrix is 4*4\n",
    "# for each flower\n",
    "for cl,mv in zip([0, 1, 2], mean_vectors):\n",
    "# scatter matrix for every class, starts with all 0's\n",
    "    class_sc_mat = np.zeros((4,4))\n",
    "# for each row that describes the specific flower\n",
    "    for row in iris_X[iris_y == cl]:\n",
    "# make column vectors\n",
    "        row, mv = row.reshape(4,1), mv.reshape(4,1)\n",
    "# this is a 4x4 matrix\n",
    "        class_sc_mat += (row-mv).dot((row-mv).T)\n",
    "# sum class scatter matrices\n",
    "        S_W += class_sc_mat\n",
    " \n",
    "S_W\n",
    "\n",
    "array([[ 38.9562, 13.683 , 24.614 , 5.6556], [ 13.683 , 17.035 , 8.12 , 4.9132], [ 24.614 , 8.12 , 27.22 , 6.2536], [ 5.6556, 4.9132, 6.2536, 6.1756]])\n",
    "\n",
    "# calculate the between-class scatter matrix\n",
    " \n",
    "# mean of entire dataset\n",
    "overall_mean = np.mean(iris_X, axis=0).reshape(4,1)\n",
    "\n",
    "# will eventually become between class scatter matrix\n",
    "S_B = np.zeros((4,4))\n",
    "for i,mean_vec in enumerate(mean_vectors):\n",
    "    # number of flowers in each species\n",
    "    n = iris_X[iris_y==i,:].shape[0]\n",
    "    # make column vector for each specied\n",
    "    mean_vec = mean_vec.reshape(4,1)\n",
    "    S_B += n * (mean_vec - overall_mean).dot((mean_vec - overall_mean).T)\n",
    " \n",
    "S_B\n",
    " \n",
    "array([[ 63.2121, -19.534 , 165.1647, 71.3631], [ -19.534 , 10.9776, -56.0552, -22.4924], [ 165.1647, -56.0552, 436.6437, 186.9081], [ 71.3631, -22.4924, 186.9081, 80.6041]])\n",
    "```\n",
    "\n",
    "The idea here is to decompose our iris dataset into two distinct parts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
